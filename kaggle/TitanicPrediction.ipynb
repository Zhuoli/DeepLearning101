{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Deep learning\n",
    "# Codelab for Titanic prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "# https://www.kaggle.com/l3nnys/titanic/dense-highway-neural-network-for-titanic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Clean data, convert non numerical data to numerical data\n",
    "# Use the Regular Expression to get the title from the name field.\n",
    "pattern = re.compile(r'.*?,(.*?)\\.')\n",
    "\n",
    "\n",
    "def getTitle(x):\n",
    "    result = pattern.search(x)\n",
    "    if result:\n",
    "        return result.group(1).strip()\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def cleanData(train, test):\n",
    "    train['Title'] = train['Name'].map(getTitle)\n",
    "    test['Title'] = test['Name'].map(getTitle)\n",
    "\n",
    "    # Set the missing Age of Title 'Master'\n",
    "    master_age_mean = train['Age'][(train['Title'] == 'Master') & (train['Age'] > 0)].mean()\n",
    "    train.loc[train[(train['Title'] == 'Master') & (train['Age'].isnull())].index, 'Age'] = master_age_mean\n",
    "    test.loc[test[(test['Title'] == 'Master') & (test['Age'].isnull())].index, 'Age'] = master_age_mean\n",
    "\n",
    "    # Set the missing Age of Title 'Mr'\n",
    "    mr_age_mean = train['Age'][(train['Title'] == 'Mr') & (train['Age'] > 0)].mean()\n",
    "    train.loc[train[(train['Title'] == 'Mr') & (train['Age'].isnull())].index, 'Age'] = mr_age_mean\n",
    "    test.loc[test[(test['Title'] == 'Mr') & (test['Age'].isnull())].index, 'Age'] = mr_age_mean\n",
    "\n",
    "    # Set the missing Age of Title 'Miss' or 'Ms'\n",
    "    miss_age_mean = train['Age'][(train['Title'] == 'Miss') & (train['Age'] > 0)].mean()\n",
    "    train.loc[train[(train['Title'] == 'Miss') & (train['Age'].isnull())].index, 'Age'] = miss_age_mean\n",
    "    test.loc[\n",
    "        test[((test['Title'] == 'Miss') | (test['Title'] == 'Ms')) & (test['Age'].isnull())].index, 'Age'] = miss_age_mean\n",
    "\n",
    "    # Set the missing Age of Title 'Mrs'\n",
    "    mrs_age_mean = train['Age'][(train['Title'] == 'Mrs') & (train['Age'] > 0)].mean()\n",
    "    train.loc[train[(train['Title'] == 'Mrs') & (train['Age'].isnull())].index, 'Age'] = mrs_age_mean\n",
    "    test.loc[test[(test['Title'] == 'Mrs') & (test['Age'].isnull())].index, 'Age'] = mrs_age_mean\n",
    "\n",
    "    # Set the missing Age of Title 'Dr'\n",
    "    dr_age_mean = train['Age'][(train['Title'] == 'Dr') & (train['Age'] > 0)].mean()\n",
    "    train.loc[train[(train['Title'] == 'Dr') & (train['Age'].isnull())].index, 'Age'] = dr_age_mean\n",
    "    test.loc[test[(test['Title'] == 'Mrs') & (test['Age'].isnull())].index, 'Age'] = dr_age_mean\n",
    "\n",
    "    sex_to_int = {'male': 1, 'female': 0}\n",
    "    train['SexInt'] = train['Sex'].map(sex_to_int)\n",
    "    embark_to_int = {'S': 0, 'C': 1, 'Q': 2}\n",
    "    train['EmbarkedInt'] = train['Embarked'].map(embark_to_int)\n",
    "    train['EmbarkedInt'] = train['EmbarkedInt'].fillna(0)\n",
    "    test['SexInt'] = test['Sex'].map(sex_to_int)\n",
    "    test['EmbarkedInt'] = test['Embarked'].map(embark_to_int)\n",
    "    test['EmbarkedInt'] = test['EmbarkedInt'].fillna(0)\n",
    "    test['Fare'] = test['Fare'].fillna(test['Fare'].mean())\n",
    "    train['FamilySize'] = train['SibSp'] + train['Parch']\n",
    "    test['FamilySize'] = test['SibSp'] + test['Parch']\n",
    "\n",
    "    ticket = train[train['Parch'] == 0]\n",
    "    ticket = ticket.loc[ticket.Ticket.duplicated(False)]\n",
    "    grouped = ticket.groupby(['Ticket'])\n",
    "    # The Friends field indicate if the passenger has frineds/SibSp in the boat.\n",
    "    train['Friends'] = 0\n",
    "    # The below fields statistic how many are survived or not survived by sex.\n",
    "    train['Male_Friends_Survived'] = 0\n",
    "    train['Male_Friends_NotSurvived'] = 0\n",
    "    train['Female_Friends_Survived'] = 0\n",
    "    train['Female_Friends_NotSurvived'] = 0\n",
    "    for (k, v) in grouped.groups.items():\n",
    "        for i in range(0, len(v)):\n",
    "            train.loc[v[i], 'Friends'] = 1\n",
    "            train.loc[v[i], 'Male_Friends_Survived'] = train[\n",
    "                (train.Ticket == k) & (train.index != v[i]) & (train.Sex == 'male') & (\n",
    "                train.Survived == 1)].Survived.count()\n",
    "            train.loc[v[i], 'Male_Friends_NotSurvived'] = train[\n",
    "                (train.Ticket == k) & (train.index != v[i]) & (train.Sex == 'male') & (\n",
    "                train.Survived == 0)].Survived.count()\n",
    "            train.loc[v[i], 'Female_Friends_Survived'] = train[\n",
    "                (train.Ticket == k) & (train.index != v[i]) & (train.Sex == 'female') & (\n",
    "                train.Survived == 1)].Survived.count()\n",
    "            train.loc[v[i], 'Female_Friends_NotSurvived'] = train[\n",
    "                (train.Ticket == k) & (train.index != v[i]) & (train.Sex == 'female') & (\n",
    "                train.Survived == 0)].Survived.count()\n",
    "\n",
    "    test_ticket = test[test['Parch'] == 0]\n",
    "    test['Friends'] = 0\n",
    "    test['Male_Friends_Survived'] = 0\n",
    "    test['Male_Friends_NotSurvived'] = 0\n",
    "    test['Female_Friends_Survived'] = 0\n",
    "    test['Female_Friends_NotSurvived'] = 0\n",
    "\n",
    "    grouped = test_ticket.groupby(['Ticket'])\n",
    "    for (k, v) in grouped.groups.items():\n",
    "        temp_df = train[train.Ticket == k]\n",
    "        length = temp_df.shape[0]\n",
    "        if temp_df.shape[0] > 0:\n",
    "            for i in range(0, len(v)):\n",
    "                test.loc[v[i], 'Friends'] = 1\n",
    "                test.loc[v[i], 'Male_Friends_Survived'] = temp_df[(temp_df.Sex == 'male') & (temp_df.Survived == 1)].shape[\n",
    "                    0]\n",
    "                test.loc[v[i], 'Male_Friends_NotSurvived'] = \\\n",
    "                temp_df[(temp_df.Sex == 'male') & (temp_df.Survived == 0)].shape[0]\n",
    "                test.loc[v[i], 'Female_Friends_Survived'] = \\\n",
    "                temp_df[(temp_df.Sex == 'female') & (temp_df.Survived == 1)].shape[0]\n",
    "                test.loc[v[i], 'Female_Friends_NotSurvived'] = \\\n",
    "                temp_df[(temp_df.Sex == 'female') & (temp_df.Survived == 0)].shape[0]\n",
    "\n",
    "    train['FatherOnBoard'] = 0\n",
    "    train['FatherSurvived'] = 0\n",
    "    train['MotherOnBoard'] = 0\n",
    "    train['MotherSurvived'] = 0\n",
    "    train['ChildOnBoard'] = 0\n",
    "    train['ChildSurvived'] = 0\n",
    "    train['ChildNotSurvived'] = 0\n",
    "    grouped = train[train.Parch > 0].groupby('Ticket')\n",
    "    for (k, v) in grouped.groups.items():\n",
    "        for i in range(0, len(v)):\n",
    "            if train.loc[v[i], 'Age'] < 19:\n",
    "                temp = train[(train.Ticket == k) & (train.Age > 18)]\n",
    "                if temp[temp.SexInt == 1].shape[0] == 1:\n",
    "                    train.loc[v[i], 'FatherOnBoard'] = 1\n",
    "                    train.loc[v[i], 'FatherSurvived'] = temp[temp.SexInt == 1].Survived.sum()\n",
    "                if temp[temp.SexInt == 0].shape[0] == 1:\n",
    "                    train.loc[v[i], 'MotherOnBoard'] = 1\n",
    "                    train.loc[v[i], 'MotherSurvived'] = temp[temp.SexInt == 0].Survived.sum()\n",
    "            else:\n",
    "                temp = train[(train.Ticket == k) & (train.Age < 19)]\n",
    "                length = temp.shape[0]\n",
    "                if length > 0:\n",
    "                    train.loc[v[i], 'ChildOnBoard'] = 1\n",
    "                    train.loc[v[i], 'ChildSurvived'] = temp[temp.Survived == 1].shape[0]\n",
    "                    train.loc[v[i], 'ChildNotSurvived'] = temp[temp.Survived == 0].shape[0]\n",
    "\n",
    "    test['FatherOnBoard'] = 0\n",
    "    test['FatherSurvived'] = 0\n",
    "    test['MotherOnBoard'] = 0\n",
    "    test['MotherSurvived'] = 0\n",
    "    test['ChildOnBoard'] = 0\n",
    "    test['ChildSurvived'] = 0\n",
    "    test['ChildNotSurvived'] = 0\n",
    "    grouped = test[test.Parch > 0].groupby('Ticket')\n",
    "    for (k, v) in grouped.groups.items():\n",
    "        temp = train[train.Ticket == k]\n",
    "        length = temp.shape[0]\n",
    "        if length > 0:\n",
    "            for i in range(0, len(v)):\n",
    "                if test.loc[v[i], 'Age'] < 19:\n",
    "                    if temp[(temp.SexInt == 1) & (temp.Age > 18)].shape[0] == 1:\n",
    "                        test.loc[v[i], 'FatherOnBoard'] = 1\n",
    "                        test.loc[v[i], 'FatherSurvived'] = temp[(temp.SexInt == 1) & (temp.Age > 18)].Survived.sum()\n",
    "                    if temp[(temp.SexInt == 0) & (temp.Age > 18)].shape[0] == 1:\n",
    "                        test.loc[v[i], 'MotherOnBoard'] = 1\n",
    "                        test.loc[v[i], 'MotherSurvived'] = temp[(temp.SexInt == 0) & (temp.Age > 18)].Survived.sum()\n",
    "                else:\n",
    "                    length = temp[temp.Age < 19].shape[0]\n",
    "                    if length > 0:\n",
    "                        test.loc[v[i], 'ChildOnBoard'] = 1\n",
    "                        test.loc[v[i], 'ChildSurvived'] = temp[(temp.Age < 19) & (temp.Survived == 1)].shape[0]\n",
    "                        test.loc[v[i], 'ChildNotSurvived'] = temp[(temp.Age < 19) & (temp.Survived == 0)].shape[0]\n",
    "\n",
    "    title_to_int = {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 1, 'Dr': 4, 'Rev': 4, 'Mlle': 2, 'Major': 4, 'Col': 4,\n",
    "                    'Ms': 3, 'Lady': 3, 'the Countess': 4, 'Sir': 4, 'Mme': 3, 'Capt': 4, 'Jonkheer': 4, 'Don': 1,\n",
    "                    'Dona': 3}\n",
    "    train['TitleInt'] = train['Title'].map(title_to_int)\n",
    "    test['TitleInt'] = test['Title'].map(title_to_int)\n",
    "    train.loc[train[train['Age'] < 13].index, 'TitleInt'] = 5\n",
    "    test.loc[test[test['Age'] < 13].index, 'TitleInt'] = 5\n",
    "\n",
    "    train['FareCat'] = pd.cut(train['Fare'], [-0.1, 50, 100, 150, 200, 300, 1000], right=True,\n",
    "                              labels=[0, 1, 2, 3, 4, 5])\n",
    "    test['FareCat'] = pd.cut(test['Fare'], [-0.1, 50, 100, 150, 200, 300, 1000], right=True,\n",
    "                             labels=[0, 1, 2, 3, 4, 5])\n",
    "    train['AgeCat'] = pd.cut(train['Age'], [-0.1, 12.1, 20, 30, 35, 40, 45, 50, 55, 65, 100], right=True,\n",
    "                             labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "    test['AgeCat'] = pd.cut(test['Age'], [-0.1, 12.1, 20, 30, 35, 40, 45, 50, 55, 65, 100], right=True,\n",
    "                            labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Defining and scaling train and test data\n",
    "# Utility split method\n",
    "def split_data(x, y, split_value, indices=None):\n",
    "    # Keeping the indices is usefull sometimes\n",
    "    if indices is None:\n",
    "        indices = np.arange(x.shape[0]) # x.shape is 2d tuple, 0 index is the row size\n",
    "        # shuffling\n",
    "        np.random.shuffle(indices)\n",
    "    data = x[indices]\n",
    "    labels = y[indices]\n",
    "    nb_test_samples = int(split_value * data.shape[0])\n",
    "    # Splitting\n",
    "    x_ = data[:-nb_test_samples] # from zero index until the last nb_test_samples index\n",
    "    y_ = labels[:-nb_test_samples]\n",
    "    _x = data[-nb_test_samples:] # from the last nb_test_samples index to end\n",
    "    _y = labels[-nb_test_samples:]\n",
    "    return x_, y_, _x, _y, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Defining and scaling train and test data\n",
    "# Utility split method\n",
    "def split_data(x, y, split_value, indices=None):\n",
    "    # Keeping the indices is usefull sometimes\n",
    "    if indices is None:\n",
    "        indices = np.arange(x.shape[0]) # x.shape is 2d tuple, 0 index is the row size\n",
    "        # shuffling\n",
    "        np.random.shuffle(indices)\n",
    "    data = x[indices]\n",
    "    labels = y[indices]\n",
    "    nb_test_samples = int(split_value * data.shape[0])\n",
    "    # Splitting\n",
    "    x_ = data[:-nb_test_samples] # from zero index until the last nb_test_samples index\n",
    "    y_ = labels[:-nb_test_samples]\n",
    "    _x = data[-nb_test_samples:] # from the last nb_test_samples index to end\n",
    "    _y = labels[-nb_test_samples:]\n",
    "    return x_, y_, _x, _y, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def standardScalerData(x_train, x_test, test, columns):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    # data scaling\n",
    "    scaler = StandardScaler()\n",
    "    scaled_x_train = scaler.fit_transform(x_train)\n",
    "    scaled_x_test = scaler.transform(x_test)\n",
    "    scaled_test = scaler.transform(test[columns])\n",
    "    return scaled_x_train, scaled_x_test, scaled_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Reading data\n",
    "# Train data\n",
    "traindata = pd.read_csv('./input/train.csv', header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "# Test data\n",
    "testdata  = pd.read_csv('./input/test.csv' , header = 0, dtype={'Age': np.float64})\n",
    "\n",
    "#Print to standard output, and see the results in the \"log\" section below after running your script\n",
    "# print(\"\\n\\nTop of the training data:\")\n",
    "# print(traindata.head())\n",
    "# print(testdata.shape)\n",
    "\n",
    "traindata, testdata = cleanData(traindata, testdata)\n",
    "\n",
    "#Print to standard output, and see the results in the \"log\" section below after running your script\n",
    "# print(\"\\n\\nTop of the training data:\")\n",
    "# print(traindata.head())\n",
    "# print(testdata.shape)\n",
    "\n",
    "\n",
    "# Defining columns to use in the model\n",
    "columns = ['Pclass', 'SexInt', 'EmbarkedInt', 'Age', 'TitleInt', 'Fare',\n",
    "           'Friends', 'Male_Friends_Survived', 'Male_Friends_NotSurvived', 'Female_Friends_Survived',\n",
    "           'Female_Friends_NotSurvived',\n",
    "           'MotherOnBoard', 'MotherSurvived', 'ChildOnBoard', 'ChildSurvived', 'ChildNotSurvived']\n",
    "\n",
    "# train/test split\n",
    "x_train, y_train, x_test, y_test, _ = split_data(traindata[columns].values, traindata['Survived'].values, 0.2)\n",
    "\n",
    "## Transform labels to one-hot encoding\n",
    "## i.e., from '7' to [0,0,0,0,0,0,0,1,0,0]\n",
    "y_train = np_utils.to_categorical(y_train, 2)\n",
    "y_test = np_utils.to_categorical(y_test, 2)\n",
    "\n",
    "scaled_x_train, scaled_x_test, scaled_test = standardScalerData(x_train=x_train, x_test=x_test, test=testdata, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense Highway Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape:   (713, 16)\n",
      "x test shape:    (178, 16)\n",
      "test shape:  (418, 16)\n",
      "[[ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# After data scalling\n",
    "print(\"x train shape:   \" + str(scaled_x_train.shape))\n",
    "print(\"x test shape:    \" + str(scaled_x_test.shape))\n",
    "print(\"test shape:  \" + str(scaled_test.shape))\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "713/713 [==============================] - 0s - loss: 0.5327 - acc: 0.7882     \n",
      "Epoch 2/20\n",
      "713/713 [==============================] - 0s - loss: 0.4012 - acc: 0.8359     \n",
      "Epoch 3/20\n",
      "713/713 [==============================] - 0s - loss: 0.3878 - acc: 0.8429     \n",
      "Epoch 4/20\n",
      "713/713 [==============================] - 0s - loss: 0.3757 - acc: 0.8359     \n",
      "Epoch 5/20\n",
      "713/713 [==============================] - 0s - loss: 0.3546 - acc: 0.8513     \n",
      "Epoch 6/20\n",
      "713/713 [==============================] - 0s - loss: 0.3554 - acc: 0.8612     \n",
      "Epoch 7/20\n",
      "713/713 [==============================] - 0s - loss: 0.3512 - acc: 0.8555     \n",
      "Epoch 8/20\n",
      "713/713 [==============================] - 0s - loss: 0.3487 - acc: 0.8499     \n",
      "Epoch 9/20\n",
      "713/713 [==============================] - 0s - loss: 0.3480 - acc: 0.8555     \n",
      "Epoch 10/20\n",
      "713/713 [==============================] - 0s - loss: 0.3413 - acc: 0.8555     \n",
      "Epoch 11/20\n",
      "713/713 [==============================] - 0s - loss: 0.3359 - acc: 0.8612     \n",
      "Epoch 12/20\n",
      "713/713 [==============================] - 0s - loss: 0.3422 - acc: 0.8612     \n",
      "Epoch 13/20\n",
      "713/713 [==============================] - 0s - loss: 0.3283 - acc: 0.8668     \n",
      "Epoch 14/20\n",
      "713/713 [==============================] - 0s - loss: 0.3232 - acc: 0.8696     \n",
      "Epoch 15/20\n",
      "713/713 [==============================] - 0s - loss: 0.3287 - acc: 0.8612     \n",
      "Epoch 16/20\n",
      "713/713 [==============================] - 0s - loss: 0.3206 - acc: 0.8654     \n",
      "Epoch 17/20\n",
      "713/713 [==============================] - 0s - loss: 0.3263 - acc: 0.8654     \n",
      "Epoch 18/20\n",
      "713/713 [==============================] - 0s - loss: 0.3298 - acc: 0.8541     \n",
      "Epoch 19/20\n",
      "713/713 [==============================] - 0s - loss: 0.3166 - acc: 0.8654     \n",
      "Epoch 20/20\n",
      "713/713 [==============================] - 0s - loss: 0.3123 - acc: 0.8752     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11a52fc88>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "#\n",
    "# First hidden layer with 'first_layer_width' neurons.\n",
    "# Also need to specify input dimension.\n",
    "# 'Dense' means fully-connected.\n",
    "dropout_rate = 0\n",
    "second_layer_width=128\n",
    "learning_rate = 0.1\n",
    "model.add(Dense(128, input_dim=scaled_x_train.shape[1], W_regularizer=None))\n",
    "model.add(Activation(\"relu\"))\n",
    "if dropout_rate > 0:\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "## Second hidden layer.\n",
    "model.add(Dense(second_layer_width))\n",
    "model.add(Activation(\"relu\"))\n",
    "if dropout_rate > 0:\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(second_layer_width))\n",
    "model.add(Activation(\"relu\"))\n",
    "if dropout_rate > 0:\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(y_train.shape[1]))\n",
    "## For classification, the activation is softmax\n",
    "model.add(Activation('softmax'))\n",
    "## Define optimizer. In this tutorial/codelab, we select SGD.\n",
    "## You can also use other methods, e.g., opt = RMSprop()\n",
    "opt = SGD(lr=learning_rate, clipnorm=5.)\n",
    "## Define loss function = 'categorical_crossentropy' or 'mean_squared_error'\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(scaled_x_train, y_train, nb_epoch=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 2)\n",
      "[[ 0.88605493  0.11394505]\n",
      " [ 0.5026198   0.4973802 ]\n",
      " [ 0.89461976  0.10538028]\n",
      " [ 0.89062792  0.10937211]\n",
      " [ 0.02646912  0.97353089]]\n",
      "(418,)\n",
      "[0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Final test predict\n",
    "test_proba = model.predict(scaled_test)\n",
    "print(test_proba.shape)\n",
    "print(test_proba[:5])\n",
    "test_classes = np_utils.probas_to_classes(test_proba)\n",
    "print(test_classes.shape)\n",
    "print(test_classes[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
