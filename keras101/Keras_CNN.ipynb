{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codelab for Convolutional Neural Net\n",
    "\n",
    "All rights reserved.<br \\>\n",
    "This material cannot be published, rewritten or redistributed in whole or part without the authors' written permission.\n",
    "\n",
    "**Convolutional Neural Net** will be abbreviated to **ConvNet** in the following sections.\n",
    "\n",
    "### Index\n",
    "1. [Pre-processing](#Pre-processing)\n",
    "2. [Recipes for ConvNet](#Recipes-Exclusively-for-Convolutional-Neural-Nets)\n",
    "    1. [Network Structure](#Network-Structure)\n",
    "        1. [Activity 1](#Tutorial/workshop-activity-1)\n",
    "    2. [Pooling](#Pooling)\n",
    "        1. [Activity 2](#Tutorial/workshop-activity-2)\n",
    "3. [Define Training Procedure](#Define-Training-Procedure)     \n",
    "4. [Start Training](#Start-Training) and [Observe Training Process](#Observe-Training-Process)\n",
    "5. [Testing](#Define-Testing-Procedure)\n",
    "\n",
    "During tutorial/workshop, attendees will be separated into three groups. Each group will be conducting different activities.<br />\n",
    "\n",
    "Activity: \"Cell\" $\\rightarrow$ \"Run All Below\" for testing the enviroment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################################################################\n",
    "#\n",
    "# All rights reserved.\n",
    "#\n",
    "# This is a codelab for Convolutional Neural Net.\n",
    "# Details include:\n",
    "#   - Pre-process dataset\n",
    "#   - Elaborate recipes\n",
    "#   - Define training procedures\n",
    "#   - Train and test models\n",
    "#   - Observe metrics\n",
    "#\n",
    "################################################################\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras.callbacks as cb\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.utils import np_utils\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "\n",
    "Pre-processing for ConvNet is slightly different than that of FNNs. Here, you need to transform the data into a 3-D tensor with dimensions [width] $\\times$ [height] $\\times$  [channel].\n",
    "\n",
    "Width and height are from a image.\n",
    "Each channel represents a color.\n",
    "\n",
    "Common techniques for data augmentation:\n",
    "1. Cropping\n",
    "2. Random cropping\n",
    "3. Rotation\n",
    "4. Add random noises\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def PreprocessDataset():\n",
    "    # Load dataset\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    # Set numeric type\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    # Normalize value to [0, 1]\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    # Transform lables to one-hot\n",
    "    y_train = np_utils.to_categorical(y_train, 10)\n",
    "    y_test = np_utils.to_categorical(y_test, 10)\n",
    "    \n",
    "    # Reshape: here x_train is re-shaped to [width] Ã— [height] x [channel]\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "    return [x_train, x_test, y_train, y_test]\n",
    "\n",
    "x_train, x_test, y_train, y_test = PreprocessDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recipes Exclusively for Convolutional Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layer\n",
    "Network structure refers to components of a convnet.\n",
    "\n",
    "Ingredients:\n",
    "1. **Filters**: define the size of a filter, and the total number of filters in a convolutional layer.\n",
    "2. **Depth** represents the number of layers, usually 10-30.\n",
    "3. **Stride** defines the step at which the filter moves.\n",
    "4. **Padding** of the input data, either no padding or zero-padding.\n",
    "\n",
    "How to calculate the number of parameters\n",
    "\n",
    "Functionalityies of convolutional layers: \n",
    "- Capture patterns\n",
    "- Share parameters (otherwise too many parameters)\n",
    "\n",
    "### Pooling\n",
    "Pooling layer reduces the output of the previous layer.\n",
    "\n",
    "max-k pool (usually k = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_filters = 16\n",
    "filter_size = 3\n",
    "\n",
    "def DefineModel():\n",
    "    model = Sequential()\n",
    "    # First conv layer with filters of 3x3 pixels; also need to specify input shape.\n",
    "    # The number of filters is set to 16 for shorter runtime.\n",
    "    # Increase the number of filters for better accuracy.\n",
    "    # Strides are defined as in subsample=(1, 1)\n",
    "    model.add(Convolution2D(num_filters, filter_size, filter_size, border_mode='valid', input_shape=(28,28,1)))\n",
    "    # Max pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # The last layer has the same dimension as the number of classes\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10))\n",
    "    # For classification, the activation is softmax\n",
    "    model.add(Activation('softmax'))\n",
    "    # Define optimizer\n",
    "    optmzr = SGD(lr=0.1, clipnorm=5.)\n",
    "    # Define loss function = cross entropy\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optmzr, metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TrainModel(data=None, epochs=20, batch=256):\n",
    "    start_time = time.time()\n",
    "    model = DefineModel()\n",
    "    if data is None:\n",
    "        print(\"Must provide data.\")\n",
    "        return\n",
    "    x_train, x_test, y_train, y_test = data\n",
    "    print(x_train.shape)\n",
    "    print(x_test.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_test.shape)\n",
    "    print(x_train[1].shape)\n",
    "    print('Start training.')\n",
    "    history = model.fit(x_train, y_train, nb_epoch=epochs, batch_size=batch,\n",
    "              validation_data=(x_test, y_test), verbose=1)\n",
    "    print(\"Training took {0} seconds.\".format(time.time() - start_time))\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "Range exceeds valid bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-fb353362f74a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-56fcbebef1aa>\u001b[0m in \u001b[0;36mTrainModel\u001b[0;34m(data, epochs, batch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mTrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDefineModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Must provide data.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-748f525a0de9>\u001b[0m in \u001b[0;36mDefineModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# The last layer has the same dimension as the number of classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# For classification, the activation is softmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zhuoli/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    330\u001b[0m                  output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    331\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/home/zhuoli/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    544\u001b[0m                                      '`layer.build(batch_input_shape)`')\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zhuoli/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    795\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{}_W'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m                                  \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m                                  constraint=self.W_constraint)\n\u001b[0m\u001b[1;32m    798\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             self.b = self.add_weight((self.output_dim,),\n",
      "\u001b[0;32m/home/zhuoli/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, shape, initializer, name, trainable, regularizer, constraint)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \"\"\"\n\u001b[1;32m    417\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregularizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zhuoli/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/initializations.py\u001b[0m in \u001b[0;36mglorot_uniform\u001b[0;34m(shape, name, dim_ordering)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mfan_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfan_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_ordering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim_ordering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfan_in\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfan_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zhuoli/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/initializations.py\u001b[0m in \u001b[0;36muniform\u001b[0;34m(shape, scale, name, dim_ordering)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_ordering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'th'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zhuoli/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36mrandom_uniform_variable\u001b[0;34m(shape, low, high, dtype, name)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrandom_uniform_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     return variable(np.random.uniform(low=low, high=high, size=shape),\n\u001b[0m\u001b[1;32m    189\u001b[0m                     dtype=dtype, name=name)\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.uniform (numpy/random/mtrand/mtrand.c:18580)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOverflowError\u001b[0m: Range exceeds valid bounds"
     ]
    }
   ],
   "source": [
    "trained_model, training_history = TrainModel(data=[x_train, x_test, y_train, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observe Training Process\n",
    "Plot the variation of loss during each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def PlotHistory(train_value, test_value, value_is_loss_or_acc):\n",
    "    f, ax = plt.subplots()\n",
    "    ax.plot([None] + train_value, 'o-')\n",
    "    ax.plot([None] + test_value, 'x-')\n",
    "    # Plot legend and use the best location automatically: loc = 0.\n",
    "    ax.legend(['Train ' + value_is_loss_or_acc, 'Validation ' + value_is_loss_or_acc], loc = 0) \n",
    "    ax.set_title('Training/Validation ' + value_is_loss_or_acc + ' per Epoch')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(value_is_loss_or_acc)  \n",
    "    \n",
    "PlotHistory(training_history.history['loss'], training_history.history['val_loss'], 'Loss')\n",
    "PlotHistory(training_history.history['acc'], training_history.history['val_acc'], 'Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TestModel(model=None, data=None):\n",
    "    if model is None:\n",
    "        print(\"Must provide a trained model.\")\n",
    "        return\n",
    "    if data is None:\n",
    "        print(\"Must provide data.\")\n",
    "        return\n",
    "    x_test, y_test = data\n",
    "    scores = model.evaluate(x_test, y_test)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_score = TestModel(model=trained_model, data=[x_test, y_test])\n",
    "print(\"Test loss {:.4f}, accuracy {:.2f}%\".format(test_score[0], test_score[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Visualize Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ShowConvolutionOutput(input_data, show_pic_idx):\n",
    "    from keras import backend as K\n",
    "    first_conv = K.function(trained_model.inputs, [trained_model.layers[1].output])\n",
    "    first_conv_out = first_conv([input_data])\n",
    "    fig, axes = plt.subplots(int(num_filters / 4), 4,figsize=(8, 8))\n",
    "    for filter_num in range(num_filters):\n",
    "        fig_x, fig_y = divmod(filter_num, 4)\n",
    "        if fig_y == 0: fig_x -= 1\n",
    "        axes[fig_x][fig_y].imshow(first_conv_out[0][show_pic_idx][:,:,filter_num])\n",
    "        plt.setp(axes[fig_x][fig_y].get_xticklabels(), visible=False)\n",
    "        plt.setp(axes[fig_x][fig_y].get_yticklabels(), visible=False)\n",
    "    fig.tight_layout(pad=0)\n",
    "    plt.show()\n",
    "\n",
    "def ShowInputImage(data):\n",
    "    plot = plt.figure()\n",
    "    plot.set_size_inches(2,2)\n",
    "    plt.imshow(np.reshape(-data, (28,28)), cmap='Greys_r')\n",
    "    plt.title(\"Input\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def ShowFinalOutput(input_data, samp):\n",
    "    \"\"\"Calculate final prediction.\"\"\"\n",
    "    from keras import backend as K\n",
    "    # Calculate final prediction.\n",
    "    last_layer = K.function(trained_model.inputs, [trained_model.layers[-1].output])\n",
    "    last_layer_out = last_layer([input_data])\n",
    "    print(\"Final prediction: \" + str(np.argmax(last_layer_out[0][samp])) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Random Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n",
    "show_which_ones = np.random.randint(0, 999, 5)\n",
    "for samp in show_which_ones:\n",
    "    ShowInputImage(x_test[samp])\n",
    "    ShowConvolutionOutput(x_test, samp)\n",
    "    ShowFinalOutput(x_test, samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
